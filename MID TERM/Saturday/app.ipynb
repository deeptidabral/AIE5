{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainlit as cl\n",
    "from chainlit.playground.providers import ChatOpenAI\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Import your travel agent components and classes\n",
    "from langchain.graphs.state import StateGraph, END\n",
    "from langchain.schema import AgentState\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import create_stuff_documents_chain, create_retrieval_chain\n",
    "\n",
    "# Define your embedding class\n",
    "class FineTunedTravelEmbeddings(Embeddings):\n",
    "    \"\"\"LangChain-compatible wrapper for the fine-tuned travel embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path=\"travel_assistant_embeddings\", device=None):\n",
    "        \"\"\"Initialize with the path to the fine-tuned model\"\"\"\n",
    "        self.model = SentenceTransformer(model_path, device=device)\n",
    "        print(f\"Loaded fine-tuned model from {model_path}\")\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Generate embeddings for a list of documents\"\"\"\n",
    "        embeddings = self.model.encode(\n",
    "            texts,\n",
    "            batch_size=32,\n",
    "            show_progress_bar=len(texts) > 50,\n",
    "            convert_to_numpy=True\n",
    "        )\n",
    "        return embeddings.tolist()\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Generate embedding for a query\"\"\"\n",
    "        embedding = self.model.encode(text, convert_to_numpy=True)\n",
    "        return embedding.tolist()\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.7)\n",
    "\n",
    "# Define RAG setup\n",
    "@cl.cache\n",
    "def setup_rag_chain_fine_tuned():\n",
    "    \"\"\"Set up the RAG chain with fine-tuned embeddings for information retrieval.\"\"\"\n",
    "    # Use the fine-tuned embeddings if available, otherwise use OpenAI embeddings\n",
    "    try:\n",
    "        embeddings = FineTunedTravelEmbeddings(model_path=\"travel_assistant_embeddings\")\n",
    "        vector_db_path = \"travel_db_fine_tuned\"\n",
    "    except Exception as e:\n",
    "        print(f\"Using default embeddings due to error: {e}\")\n",
    "        from langchain_openai import OpenAIEmbeddings\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        vector_db_path = \"travel_db_faiss\"\n",
    "    \n",
    "    # Load the vector store\n",
    "    try:\n",
    "        travel_db = FAISS.load_local(\n",
    "            vector_db_path, \n",
    "            embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        \n",
    "        # Load the docstore if it exists\n",
    "        import pickle\n",
    "        import os\n",
    "        docstore_path = f\"{vector_db_path}_docstore.pkl\"\n",
    "        if os.path.exists(docstore_path):\n",
    "            with open(docstore_path, 'rb') as f:\n",
    "                travel_db.docstore = pickle.load(f)\n",
    "        \n",
    "        print(f\"Loaded knowledge base with {len(travel_db.index_to_docstore_id)} documents\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading vector store: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Create a retriever\n",
    "    retriever = travel_db.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 7}\n",
    "    )\n",
    "        \n",
    "    rag_prompt = ChatPromptTemplate.from_template(\"\"\"You are a knowledgeable travel assistant with expertise in destinations worldwide.\n",
    "        Use the following travel information to provide detailed, accurate responses to the user's query.\n",
    "        If the retrieved information doesn't fully answer the question, use your knowledge to provide\n",
    "        the best possible response, but prioritize the retrieved information.\n",
    "        \n",
    "        Retrieved information: {context}        \n",
    "        Question: {input}\n",
    "    \"\"\")\n",
    "\n",
    "    # Create the document processing chain\n",
    "    document_chain = create_stuff_documents_chain(llm, rag_prompt)\n",
    "    \n",
    "    return create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "# Define agent functions\n",
    "def router_agent(state: AgentState) -> dict:\n",
    "    \"\"\"Router agent that determines which specialized agent should handle the query.\"\"\"\n",
    "    router_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a travel assistant router. Your job is to determine which specialized agent\n",
    "        should handle the user's travel-related query. Choose the most appropriate agent from:\n",
    "        \n",
    "        - itinerary_agent: For requests to create travel itineraries, vacation plans, or multi-day travel schedules\n",
    "        - flight_agent: For questions about flights, airfares, airlines, or flight bookings\n",
    "        - accommodation_agent: For questions about hotels, resorts, accommodations, or places to stay\n",
    "        - information_agent: For general travel information, destination facts, or travel advice\n",
    "        \n",
    "        Respond ONLY with the name of the appropriate agent. Do not include any explanations or additional text.\n",
    "        \"\"\"),\n",
    "        (\"human\", \"{query}\")\n",
    "    ])\n",
    "    \n",
    "    chain = router_prompt | llm | StrOutputParser()\n",
    "    agent_executor = chain.invoke({\"query\": state.query}).strip()\n",
    "    \n",
    "    valid_agents = [\"itinerary_agent\", \"flight_agent\", \"accommodation_agent\", \"information_agent\"]\n",
    "    if agent_executor not in valid_agents:\n",
    "        agent_executor = \"information_agent\"\n",
    "            \n",
    "    return {\"agent_executor\": agent_executor, \n",
    "            \"query\": state.query,\n",
    "            \"chat_history\": state.chat_history,\n",
    "            \"agent_response\": state.agent_response,\n",
    "            \"final_response\": state.final_response,\n",
    "            \"context\": state.context,\n",
    "            \"error\": state.error}\n",
    "\n",
    "def itinerary_agent(state: AgentState) -> dict:\n",
    "    \"\"\"Creates personalized travel itineraries.\"\"\"\n",
    "    try:\n",
    "        # Extract context from state or initialize empty dict\n",
    "        context = state.context or {}\n",
    "        \n",
    "        # Extract entities from the user's query\n",
    "        extraction_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are a travel analysis assistant. Extract key information from the user's query.\n",
    "            Return a JSON object with these fields (leave empty strings if not mentioned):\n",
    "            {\n",
    "                \"destinations\": [\"list of destination cities or countries\"],\n",
    "                \"duration\": \"duration of the trip mentioned (e.g., '5 days', '1 week')\",\n",
    "                \"budget\": \"any budget information (e.g., 'luxury', 'budget-friendly')\",\n",
    "                \"interests\": [\"list of mentioned activities or interests\"],\n",
    "                \"travel_dates\": \"when they plan to travel\",\n",
    "                \"travelers\": \"information about who is traveling (e.g., 'family with kids', 'solo')\"\n",
    "            }\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{query}\")\n",
    "        ])\n",
    "        \n",
    "        extraction_chain = extraction_prompt | llm | StrOutputParser()\n",
    "        \n",
    "        try:\n",
    "            extracted_info = json.loads(extraction_chain.invoke({\"query\": state.query}))\n",
    "            context.update(extracted_info)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "        \n",
    "        # Generate the itinerary\n",
    "        itinerary_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are a travel itinerary expert who creates detailed, personalized travel plans.\n",
    "            Create a comprehensive day-by-day itinerary for the user's request, including:\n",
    "            \n",
    "            - Appropriate pacing with realistic timing for activities\n",
    "            - A variety of activities tailored to the mentioned interests\n",
    "            - Specific recommendations for attractions, restaurants, and transportation\n",
    "            - Practical travel tips related to the destination(s)\n",
    "            - Brief contextual information about key attractions\n",
    "            \n",
    "            If certain details (like budget, dates, or interests) aren't specified, make balanced recommendations\n",
    "            that would appeal to most travelers. Format the response with clear headings and organize by days.\n",
    "            \"\"\"),\n",
    "            (\"human\", \"\"\"{query}\n",
    "            \n",
    "            Travel Details:\n",
    "            - Destinations: {destinations}\n",
    "            - Duration: {duration}\n",
    "            - When: {travel_dates}\n",
    "            - Budget: {budget}\n",
    "            - Interests: {interests}\n",
    "            - Travelers: {travelers}\n",
    "            \"\"\")\n",
    "        ])\n",
    "        \n",
    "        itinerary_chain = itinerary_prompt | llm | StrOutputParser()\n",
    "        \n",
    "        destinations_str = \", \".join(context.get(\"destinations\", []))\n",
    "        interests_str = \", \".join(context.get(\"interests\", []))\n",
    "        \n",
    "        response = itinerary_chain.invoke({\n",
    "            \"query\": state.query,\n",
    "            \"destinations\": destinations_str,\n",
    "            \"duration\": context.get(\"duration\", \"\"),\n",
    "            \"budget\": context.get(\"budget\", \"\"),\n",
    "            \"interests\": interests_str,\n",
    "            \"travel_dates\": context.get(\"travel_dates\", \"\"),\n",
    "            \"travelers\": context.get(\"travelers\", \"\")\n",
    "        })\n",
    "        \n",
    "        return {\"agent_response\": response, \"context\": context}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def flight_agent(state: AgentState) -> dict:\n",
    "    \"\"\"Provides flight information and recommendations.\"\"\"\n",
    "    try:\n",
    "        # Extract flight-related parameters\n",
    "        extraction_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"Extract flight search parameters from the user's query.\n",
    "            Return a JSON object with these fields (leave empty if not mentioned):\n",
    "            {\n",
    "                \"origin\": \"departure city or airport\",\n",
    "                \"destination\": \"arrival city or airport\",\n",
    "                \"departure_date\": \"in YYYY-MM-DD format if possible\",\n",
    "                \"return_date\": \"in YYYY-MM-DD format if possible\",\n",
    "                \"passengers\": \"number of passengers\",\n",
    "                \"class\": \"economy, business, or first class\",\n",
    "                \"preferences\": [\"non-stop\", \"specific airline\", etc.]\n",
    "            }\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{query}\")\n",
    "        ])\n",
    "        \n",
    "        extraction_chain = extraction_prompt | llm | StrOutputParser()\n",
    "        try:\n",
    "            flight_params = json.loads(extraction_chain.invoke({\"query\": state.query}))\n",
    "            state.context = {**state.context, \"flight_params\": flight_params} if state.context else {\"flight_params\": flight_params}\n",
    "        except json.JSONDecodeError:\n",
    "            state.context = state.context or {}\n",
    "        \n",
    "        # Get flight information using RAG\n",
    "        rag_chain = setup_rag_chain_fine_tuned()\n",
    "        retrieval_result = rag_chain.invoke({\"input\": state.query})\n",
    "        \n",
    "        # Generate response\n",
    "        flight_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are a flight expert. Provide detailed flight information and recommendations\n",
    "            based on the user's query and the retrieved data. Include:\n",
    "            \n",
    "            - Flight options including airlines and typical schedules\n",
    "            - Estimated price ranges\n",
    "            - Booking recommendations and timing advice\n",
    "            - Airport tips and information\n",
    "            - Seasonal considerations for the route\n",
    "            \n",
    "            If specific flight data isn't available, provide general advice about flights for the\n",
    "            requested route, typical costs, best booking times, and airlines that service the route.\n",
    "            \n",
    "            Retrieved flight information:\n",
    "            {context}\n",
    "            \n",
    "            Extracted flight parameters:\n",
    "            {flight_params}\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{query}\")\n",
    "        ])\n",
    "        \n",
    "        flight_chain = flight_prompt | llm | StrOutputParser()\n",
    "        response = flight_chain.invoke({\n",
    "            \"query\": state.query,\n",
    "            \"context\": retrieval_result.get(\"answer\", \"\"),\n",
    "            \"flight_params\": json.dumps(state.context.get(\"flight_params\", {}), indent=2)\n",
    "        })\n",
    "        \n",
    "        return {\"agent_response\": response}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def accommodation_agent(state: AgentState) -> dict:\n",
    "    \"\"\"Provides hotel and accommodation recommendations.\"\"\"\n",
    "    try:\n",
    "        # Extract accommodation preferences\n",
    "        extraction_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"Extract accommodation preferences from the user's query.\n",
    "            Return a JSON object with these fields (leave empty if not mentioned):\n",
    "            {\n",
    "                \"location\": \"city or specific area\",\n",
    "                \"check_in_date\": \"in YYYY-MM-DD format\",\n",
    "                \"check_out_date\": \"in YYYY-MM-DD format\",\n",
    "                \"guests\": \"number of guests\",\n",
    "                \"rooms\": \"number of rooms\",\n",
    "                \"budget_range\": \"price range per night\"\n",
    "            }\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{query}\")\n",
    "        ])\n",
    "        \n",
    "        extraction_chain = extraction_prompt | llm | StrOutputParser()\n",
    "        try:\n",
    "            accommodation_params = json.loads(extraction_chain.invoke({\"query\": state.query}))\n",
    "            state.context = {**state.context, \"accommodation_params\": accommodation_params} if state.context else {\"accommodation_params\": accommodation_params}\n",
    "        except json.JSONDecodeError:\n",
    "            state.context = state.context or {}\n",
    "        \n",
    "        # Get accommodation information using RAG\n",
    "        rag_chain = setup_rag_chain_fine_tuned()\n",
    "        retrieval_result = rag_chain.invoke({\"input\": f\"hotels in {state.context.get('accommodation_params', {}).get('location', '')}\"})\n",
    "        \n",
    "        # Generate response\n",
    "        accommodation_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are a hotel and accommodation expert. Provide detailed recommendations\n",
    "            based on the user's preferences and the retrieved accommodation data. Include:\n",
    "            \n",
    "            - Suitable hotel/accommodation options\n",
    "            - Price ranges and value considerations\n",
    "            - Location benefits and proximity to attractions\n",
    "            - Amenities and facilities\n",
    "            - Guest ratings and reviews summary\n",
    "            - Booking tips and optimal timing\n",
    "            \n",
    "            If specific accommodation data isn't available, provide general advice about\n",
    "            accommodations in the requested location, typical options at different price points,\n",
    "            and best areas to stay.\n",
    "            \n",
    "            Retrieved accommodation information:\n",
    "            {context}\n",
    "            \n",
    "            Extracted accommodation parameters:\n",
    "            {accommodation_params}\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{query}\")\n",
    "        ])\n",
    "        \n",
    "        accommodation_chain = accommodation_prompt | llm | StrOutputParser()\n",
    "        response = accommodation_chain.invoke({\n",
    "            \"query\": state.query,\n",
    "            \"context\": retrieval_result.get(\"answer\", \"\"),\n",
    "            \"accommodation_params\": json.dumps(state.context.get(\"accommodation_params\", {}), indent=2)\n",
    "        })\n",
    "        \n",
    "        return {\"agent_response\": response}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def information_agent(state: AgentState) -> dict:\n",
    "    \"\"\"Answers general travel questions using RAG.\"\"\"\n",
    "    try:\n",
    "        # Use RAG chain for travel information\n",
    "        rag_chain = setup_rag_chain_fine_tuned()\n",
    "        result = rag_chain.invoke({\"input\": state.query})\n",
    "        \n",
    "        # Enhance RAG response\n",
    "        enhancement_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are a knowledgeable travel information specialist. Review and enhance\n",
    "            the retrieved information to provide a comprehensive, accurate response to the user's query.\n",
    "            \n",
    "            If the retrieved information is incomplete, add relevant details from your knowledge while\n",
    "            clearly distinguishing between retrieved facts and general knowledge.\n",
    "            \n",
    "            Focus on providing practical, useful information that directly addresses the user's needs.\n",
    "            Include cultural insights, traveler tips, and seasonal considerations when relevant.\n",
    "            \n",
    "            Retrieved information:\n",
    "            {rag_response}\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        \n",
    "        enhancement_chain = enhancement_prompt | llm | StrOutputParser()\n",
    "        enhanced_response = enhancement_chain.invoke({\n",
    "            \"input\": state.query,\n",
    "            \"rag_response\": result.get(\"answer\", \"\")\n",
    "        })\n",
    "        \n",
    "        return {\"agent_response\": enhanced_response}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def generate_final_response(state: AgentState) -> dict:\n",
    "    \"\"\"Generates the final, polished response to the user.\"\"\"\n",
    "    formatting_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a friendly, helpful travel assistant. Format the specialized agent's response\n",
    "        into a clear, well-structured, and engaging reply. Maintain all the factual information and advice\n",
    "        while improving readability with:\n",
    "        \n",
    "        - A warm, conversational tone\n",
    "        - Logical organization with headings where appropriate\n",
    "        - Bullet points for lists\n",
    "        - Bold text for important information\n",
    "        - Emojis where appropriate (but not excessive)\n",
    "        \n",
    "        Make sure the response completely addresses the user's query. Add a brief, friendly closing\n",
    "        that invites further questions.\n",
    "        \n",
    "        Original agent response:\n",
    "        {agent_response}\n",
    "        \"\"\"),\n",
    "        (\"human\", \"{query}\")\n",
    "    ])\n",
    "    \n",
    "    formatting_chain = formatting_prompt | llm | StrOutputParser()\n",
    "    final_response = formatting_chain.invoke({\n",
    "        \"query\": state.query,\n",
    "        \"agent_response\": state.agent_response\n",
    "    })\n",
    "    \n",
    "    return {\"agent_response\": final_response}\n",
    "\n",
    "def handle_error(state: AgentState) -> dict:\n",
    "    \"\"\"Handles errors and provides a graceful fallback response.\"\"\"\n",
    "    error_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a helpful travel assistant. The system encountered an error while\n",
    "        processing the user's query. Provide a helpful response that:\n",
    "        \n",
    "        1. Acknowledges the issue\n",
    "        2. Offers general travel advice related to their query\n",
    "        3. Suggests how they might rephrase their question for better results\n",
    "        \n",
    "        Error message: {error}\n",
    "        \"\"\"),\n",
    "        (\"human\", \"{query}\")\n",
    "    ])\n",
    "    \n",
    "    error_chain = error_prompt | llm | StrOutputParser()\n",
    "    fallback_response = error_chain.invoke({\n",
    "        \"query\": state.query,\n",
    "        \"error\": state.error or \"Unknown error occurred\"\n",
    "    })\n",
    "    \n",
    "    return {\"agent_response\": fallback_response}\n",
    "\n",
    "def create_travel_assistant_graph():\n",
    "    \"\"\"Creates the travel assistant graph using LangGraph.\"\"\"\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"router\", router_agent)\n",
    "    workflow.add_node(\"itinerary_agent\", itinerary_agent)\n",
    "    workflow.add_node(\"flight_agent\", flight_agent)\n",
    "    workflow.add_node(\"accommodation_agent\", accommodation_agent)\n",
    "    workflow.add_node(\"information_agent\", information_agent)\n",
    "    workflow.add_node(\"response_generator\", generate_final_response)\n",
    "    workflow.add_node(\"error_handler\", handle_error)\n",
    "    \n",
    "    # Define conditional edge routing\n",
    "    def router_edges(state):\n",
    "        if state.agent_executor == \"itinerary_agent\":\n",
    "            return \"itinerary_agent\"\n",
    "        elif state.agent_executor == \"flight_agent\":\n",
    "            return \"flight_agent\"\n",
    "        elif state.agent_executor == \"accommodation_agent\":\n",
    "            return \"accommodation_agent\"\n",
    "        else:\n",
    "            return \"information_agent\"\n",
    "    \n",
    "    def agent_edges(state):\n",
    "        if state.error is not None:\n",
    "            return \"error_handler\"\n",
    "        else:\n",
    "            return \"response_generator\"\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"router\")\n",
    "    \n",
    "    # Connect router to agents\n",
    "    workflow.add_conditional_edges(\"router\", router_edges)\n",
    "    \n",
    "    # Connect agents to next nodes\n",
    "    for agent in [\"itinerary_agent\", \"flight_agent\", \"accommodation_agent\", \"information_agent\"]:\n",
    "        workflow.add_conditional_edges(agent, agent_edges)\n",
    "    \n",
    "    # Connect to end\n",
    "    workflow.add_edge(\"response_generator\", END)\n",
    "    workflow.add_edge(\"error_handler\", END)\n",
    "    \n",
    "    # Compile the graph\n",
    "    return workflow.compile()\n",
    "\n",
    "# Initialize the travel assistant\n",
    "travel_assistant = create_travel_assistant_graph()\n",
    "\n",
    "# Chainlit code\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    await cl.Message(content=\"ðŸ‘‹ Hi there! I'm your AI Travel Assistant. Whether you need help planning an itinerary, finding flights, booking accommodations, or just want travel information, I'm here to help. What can I assist you with today?\").send()\n",
    "    cl.user_session.set(\"travel_assistant\", travel_assistant)\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(message: cl.Message):\n",
    "    travel_assistant = cl.user_session.get(\"travel_assistant\")\n",
    "    \n",
    "    # Show thinking message\n",
    "    thinking_msg = cl.Message(content=\"Thinking...\", author=\"Travel Assistant\")\n",
    "    await thinking_msg.send()\n",
    "    \n",
    "    # Process the query\n",
    "    try:\n",
    "        # Extract previous messages for chat history\n",
    "        chat_history = []\n",
    "        for msg in cl.user_session.get(\"message_history\", []):\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                chat_history.append({\"role\": \"user\", \"content\": msg[\"content\"]})\n",
    "            else:\n",
    "                chat_history.append({\"role\": \"assistant\", \"content\": msg[\"content\"]})\n",
    "        \n",
    "        # Call the travel assistant\n",
    "        result = travel_assistant.invoke({\n",
    "            \"query\": message.content,\n",
    "            \"chat_history\": chat_history\n",
    "        })\n",
    "        \n",
    "        # Store this exchange in chat history\n",
    "        if \"message_history\" not in cl.user_session:\n",
    "            cl.user_session.set(\"message_history\", [])\n",
    "        \n",
    "        cl.user_session.get(\"message_history\").append({\"role\": \"user\", \"content\": message.content})\n",
    "        cl.user_session.get(\"message_history\").append({\"role\": \"assistant\", \"content\": result[\"agent_response\"]})\n",
    "        \n",
    "        # Update thinking message with the response\n",
    "        await thinking_msg.update(content=result[\"agent_response\"])\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_msg = f\"Error processing your request: {str(e)}\\n\\n{traceback.format_exc()}\"\n",
    "        await thinking_msg.update(content=f\"I encountered an error while processing your request. Please try again with a more specific travel question.\")\n",
    "        print(error_msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
