{"questions": {"8768e4e4-7ec4-49fc-941c-1b2098509346": "QUESTION #1\\n", "24745cde-3e30-4de8-bf0d-35062b818016": "QUESTION #2\\n...\\n\\nContext:\\nIs this infrastructure necessary? DeepSeek v3\u2019s $6m training cost and the continued crash in LLM prices might hint that it\u2019s not. But would you want to be the big tech executive that argued NOT to build out this infrastructure only to be proven wrong in a few years\u2019 time?\\n\\nAn interesting point of comparison here could be the way railways rolled out around the world in the 1800s. Constructing these required enormous investments and had a massive environmental impact, and many of the lines that were built turned out to be unnecessary\u2014sometimes multiple lines from different companies serving the exact same routes!\\n', additional_kwargs={}, response_metadata={})]", "e6ebde2c-e0a0-4c7e-a914-3724654d187f": "QUESTION #1\\n", "7c77ef8c-04c4-405b-9bcc-49e91330e814": "QUESTION #2\\n...\\n\\nContext:\\nThe resulting bubbles contributed to several financial crashes, see Wikipedia for Panic of 1873, Panic of 1893, Panic of 1901 and the UK\u2019s Railway Mania. They left us with a lot of useful infrastructure and a great deal of bankruptcies and environmental damage.\\n\\nThe year of slop\\n\\n2024 was the year that the word \"slop\" became a term of art. I wrote about this in May, expanding on this tweet by @deepfates:\\n\\nWatching in real time as \u201cslop\u201d becomes a term of art. the way that \u201cspam\u201d became the term for unwanted emails, \u201cslop\u201d is going in the dictionary as the term for unwanted AI generated content\\n\\nI expanded that definition a tiny bit to this:\\n\\nSlop describes AI-generated content that is both unrequested and unreviewed.\\n', additional_kwargs={}, response_metadata={})]", "c4b4727c-e386-4590-a5d5-a395ceb69f0c": "QUESTION #1\\n", "af9d6b48-d777-4f45-b968-7885ee934b5b": "QUESTION #2\\n...\\n\\nContext:\\nI ended up getting quoted talking about slop in both the Guardian and the NY Times. Here\u2019s what I said in the NY TImes:\\n\\nSociety needs concise ways to talk about modern A.I. \u2014 both the positives and the negatives. \u2018Ignore that email, it\u2019s spam,\u2019 and \u2018Ignore that article, it\u2019s slop,\u2019 are both useful lessons.\\n\\nI love the term \u201cslop\u201d because it so succinctly captures one of the ways we should not be using generative AI!\\n\\nSlop was even in the running for Oxford Word of the Year 2024, but it lost to brain rot.\\n\\nSynthetic training data works great\\n', additional_kwargs={}, response_metadata={})]", "7de941f6-cfa1-4e97-a090-02168358c173": "QUESTION #1\\n", "14242c09-10d7-4950-82cd-82cedcbfd5ba": "QUESTION #2\\n...\\n\\nContext:\\nAn idea that surprisingly seems to have stuck in the public consciousness is that of \u201cmodel collapse\u201d. This was first described in the paper The Curse of Recursion: Training on Generated Data Makes Models Forget in May 2023, and repeated in Nature in July 2024 with the more eye-catching headline AI models collapse when trained on recursively generated data.\\n\\nThe idea is seductive: as the internet floods with AI-generated slop the models themselves will degenerate, feeding on their own output in a way that leads to their inevitable demise!\\n\\nThat\u2019s clearly not happening. Instead, we are seeing AI labs increasingly train on synthetic content\u2014deliberately creating artificial data to help steer their models in the right way.\\n', additional_kwargs={}, response_metadata={})]", "93abed6b-9015-4842-96bf-8fb347f10bd9": "QUESTION #1\\n", "a1a28982-4c66-43e0-a981-652668f207bc": "QUESTION #2\\n...\\n\\nContext:\\nOne of the best descriptions I\u2019ve seen of this comes from the Phi-4 technical report, which included this:\\n\\nSynthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data.\\n', additional_kwargs={}, response_metadata={})]", "074d1058-379a-45db-b6c8-65a436f71de9": "QUESTION #1\\n", "cac6a4a3-e5f3-4a14-b5e0-a9203bac705d": "QUESTION #2\\n...\\n\\nContext:\\nStructured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns.\\n', additional_kwargs={}, response_metadata={})]", "e07e88c3-efd4-4f88-a757-156eae525cfc": "QUESTION #1\\n", "669cd88e-caa5-430a-bed7-040845c30646": "QUESTION #2\\n...\\n\\nContext:\\nAnother common technique is to use larger models to help create training data for their smaller, cheaper alternatives\u2014a trick used by an increasing number of labs. DeepSeek v3 used \u201creasoning\u201d data created by DeepSeek-R", "e250bb36-e8f1-455e-8630-677607266f04": "Meta\u2019s Llama", "1fe318c7-1bd9-4313-8d8e-000444fdfa97": "QUESTION #1\\n", "aafcb174-d4e0-403a-96c2-efa6f1f87567": "QUESTION #2\\n...\\n\\nContext:\\nA drum I\u2019ve been banging for a while is that LLMs are power-user tools\u2014they\u2019re chainsaws disguised as kitchen knives. They look deceptively simple to use\u2014how hard can it be to type messages to a chatbot?\u2014but in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls.\\n\\nIf anything, this problem got worse in", "d9355f84-7322-4ec9-af37-bec601e80d0f": "QUESTION #1\\n", "c9e5f27e-aae9-4faf-8bf0-8a6b3155463e": "QUESTION #2\\n...\\n\\nContext:\\nThe number of available systems has exploded. Different systems have different tools they can apply to your problems\u2014like Python and JavaScript and web search and image generation and maybe even database lookups... so you\u2019d better understand what those tools are, what they can do and how to tell if the LLM used them or not.\\n\\nDid you know ChatGPT has two entirely different ways of running Python now?\\n\\nWant to build a Claude Artifact that talks to an external API? You\u2019d better understand CSP and CORS HTTP headers first.\\n', additional_kwargs={}, response_metadata={})]", "68c62e0f-03b8-4c8a-9bc2-4a7623e245e3": "QUESTION #1\\n", "54c75aad-4dd0-4e76-ba65-5cbb3119d404": "QUESTION #2\\n...\\n\\nContext:\\nThe models may have got more capable, but most of the limitations remained the same. OpenAI\u2019s o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it\u2019s running in. o1 can\u2019t run web searches or use Code Interpreter, but GPT-4o can\u2014both in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023).\\n\\nWhat are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out.\\n', additional_kwargs={}, response_metadata={})]", "9c506641-a993-4020-bda5-a7168b5fd35d": "QUESTION #1\\n", "b9354d3f-0ab2-4113-8435-6e25215c091e": "QUESTION #2\\n...\\n\\nContext:\\nMeanwhile, it\u2019s increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I\u2019ve seen so many examples of people trying to win an argument with a screenshot from ChatGPT\u2014an inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right.\\n', additional_kwargs={}, response_metadata={})]", "2f143385-9694-4a81-a29b-b39f267d9c23": "QUESTION #1\\n", "786caadb-5ac5-4b68-ab5e-39f2a38f29b4": "QUESTION #2\\n...\\n\\nContext:\\nThere\u2019s a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can\u2019t see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire!\\n\\nThere is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads.\\n\\nKnowledge is incredibly unevenly distributed\\n\\nMost people have heard of ChatGPT by now. How many have heard of Claude?\\n', additional_kwargs={}, response_metadata={})]", "00a454dd-9cce-4d62-902c-b0cd0ac33134": "QUESTION #1\\n", "e2bacecc-2956-4591-bdde-ccab2fe92130": "QUESTION #2\\n...\\n\\nContext:\\nThe knowledge gap between the people who actively follow this stuff and the 99% of the population who do not is vast.\\n\\nThe pace of change doesn\u2019t help either. In just the past month we\u2019ve seen general availability of live interfaces where you can point your phone\u2019s camera at something and talk about it with your voice... and optionally have it pretend to be Santa. Most self-certified nerds haven\u2019t even tried that yet.\\n\\nGiven the ongoing (and potential) impact on society that this technology has, I don\u2019t think the size of this gap is healthy. I\u2019d like to see a lot more effort put into improving this.\\n\\nLLMs need better criticism\\n', additional_kwargs={}, response_metadata={})]", "0bae2cd2-9509-438a-a4ac-b5089822db45": "QUESTION #1\\n", "b9793dff-5675-45ac-918c-8913dacaf24e": "QUESTION #2\\n...\\n\\nContext:\\nA lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that \u201cLLMs are useful\u201d can be enough to kick off a huge fight.\\n\\nI get it. There are plenty of reasons to dislike this technology\u2014the environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people\u2019s jobs.\\n\\nLLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative.\\n', additional_kwargs={}, response_metadata={})]", "3fae2487-25fa-4f7f-83ae-5b58ca79fcd2": "QUESTION #1\\n", "bf78914e-2a0e-4049-b6c4-873ecaffc9f0": "QUESTION #2\\n...\\n\\nContext:\\nI like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot of very bad decisions are being made based on that hype. Being critical is a virtue.\\n\\nIf we want people with decision-making authority to make good decisions about how to apply these tools we first need to acknowledge that there ARE good applications, and then help explain how to put those into practice while avoiding the many unintiutive traps.\\n\\n(If you still don\u2019t think there are any good applications at all I\u2019m not sure why you made it to this point in the article!)\\n', additional_kwargs={}, response_metadata={})]", "8f7ba8bd-968d-4ce2-9e6c-6a56f87d32ed": "QUESTION #1\\n", "75280ba6-688c-419a-8a93-20cf5b07a15f": "QUESTION #2\\n...\\n\\nContext:\\nI think telling people that this whole field is environmentally catastrophic plagiarism machines that constantly make things up is doing those people a disservice, no matter how much truth that represents. There is genuine value to be had here, but getting to that value is unintuitive and needs guidance.\\n\\nThose of us who understand this stuff have a duty to help everyone else figure it out.\\n\\nEverything tagged \u201cllms\u201d on my blog in 2024\\n\\nBecause I undoubtedly missed a whole bunch of things, here\u2019s every long-form post I wrote in 2024 that I tagged with llms:\\n\\nJanuary\\n\\n7th: It\u2019s OK to call it Artificial Intelligence\\n\\n9th: What I should have said about the term Artificial Intelligence\\n\\n17th: Talking about Open Source LLMs on Oxide and Friends\\n', additional_kwargs={}, response_metadata={})]", "fe569c3a-eb38-4d80-b8d5-5e50ca70cf34": "QUESTION #1\\n", "42f6b56a-8e64-42ff-9ecb-de84650fb057": "QUESTION #2\\n...\\n\\nContext:\\n26th: LLM", "db0afe55-ce59-4886-b096-029954797356": "QUESTION #1\\n", "0d5cbffc-9c1c-4a6a-a8e5-66c442342fb4": "QUESTION #2\\n...\\n\\nContext:\\nMay\\n\\n8th: Slop is the new name for unwanted AI-generated content\\n\\n15th: ChatGPT in \u201c4o\u201d mode is not running the new features yet\\n\\n29th: Training is not the same as chatting: ChatGPT and other LLMs don\u2019t remember everything you say\\n\\nJune\\n\\n6th: Accidental prompt injection against RAG applications\\n\\n10th: Thoughts on the WWDC 2024 keynote on Apple Intelligence\\n\\n17th: Language models on the command-line\\n\\n21st: Building search-based RAG using Claude, Datasette and Val Town\\n\\n27th: Open challenges for AI engineering\\n\\nJuly\\n\\n14th: Imitation Intelligence, my keynote for PyCon US 2024\\n\\n19th: Weeknotes: GPT-4o mini, LLM"}, "relevant_contexts": {"8768e4e4-7ec4-49fc-941c-1b2098509346": ["982bddd4-34de-4203-aa57-d54c408be112"], "24745cde-3e30-4de8-bf0d-35062b818016": ["982bddd4-34de-4203-aa57-d54c408be112"], "e6ebde2c-e0a0-4c7e-a914-3724654d187f": ["45c2370e-5759-4478-b1e4-efceef0e3903"], "7c77ef8c-04c4-405b-9bcc-49e91330e814": ["45c2370e-5759-4478-b1e4-efceef0e3903"], "c4b4727c-e386-4590-a5d5-a395ceb69f0c": ["abfc7d71-9abd-4e1a-88c6-58cab4f9847e"], "af9d6b48-d777-4f45-b968-7885ee934b5b": ["abfc7d71-9abd-4e1a-88c6-58cab4f9847e"], "7de941f6-cfa1-4e97-a090-02168358c173": ["aafd1862-f236-4592-858b-f010bee67ce0"], "14242c09-10d7-4950-82cd-82cedcbfd5ba": ["aafd1862-f236-4592-858b-f010bee67ce0"], "93abed6b-9015-4842-96bf-8fb347f10bd9": ["e3dbbc53-911e-4237-a5bc-6b07c6de23e5"], "a1a28982-4c66-43e0-a981-652668f207bc": ["e3dbbc53-911e-4237-a5bc-6b07c6de23e5"], "074d1058-379a-45db-b6c8-65a436f71de9": ["445f11d6-c052-46bc-9372-7bb3c3321b77"], "cac6a4a3-e5f3-4a14-b5e0-a9203bac705d": ["445f11d6-c052-46bc-9372-7bb3c3321b77"], "e07e88c3-efd4-4f88-a757-156eae525cfc": ["7b2e4741-c4a8-4368-8483-9163f636eced"], "669cd88e-caa5-430a-bed7-040845c30646": ["7b2e4741-c4a8-4368-8483-9163f636eced"], "e250bb36-e8f1-455e-8630-677607266f04": ["7b2e4741-c4a8-4368-8483-9163f636eced"], "1fe318c7-1bd9-4313-8d8e-000444fdfa97": ["af2325a7-de09-4e9b-8f17-57c5f19b92ec"], "aafcb174-d4e0-403a-96c2-efa6f1f87567": ["af2325a7-de09-4e9b-8f17-57c5f19b92ec"], "d9355f84-7322-4ec9-af37-bec601e80d0f": ["fe888d58-fc47-4355-bfd6-a349eb4ff35f"], "c9e5f27e-aae9-4faf-8bf0-8a6b3155463e": ["fe888d58-fc47-4355-bfd6-a349eb4ff35f"], "68c62e0f-03b8-4c8a-9bc2-4a7623e245e3": ["840cbf06-ab90-4d11-a9f9-8d92e31444f0"], "54c75aad-4dd0-4e76-ba65-5cbb3119d404": ["840cbf06-ab90-4d11-a9f9-8d92e31444f0"], "9c506641-a993-4020-bda5-a7168b5fd35d": ["735cf492-c1fc-4edf-95a1-891bfac88f13"], "b9354d3f-0ab2-4113-8435-6e25215c091e": ["735cf492-c1fc-4edf-95a1-891bfac88f13"], "2f143385-9694-4a81-a29b-b39f267d9c23": ["210c19b2-e524-45a9-8aba-3635b6f9c15c"], "786caadb-5ac5-4b68-ab5e-39f2a38f29b4": ["210c19b2-e524-45a9-8aba-3635b6f9c15c"], "00a454dd-9cce-4d62-902c-b0cd0ac33134": ["ba7f8038-b4e1-42e7-8ae3-4f53b7d5f57c"], "e2bacecc-2956-4591-bdde-ccab2fe92130": ["ba7f8038-b4e1-42e7-8ae3-4f53b7d5f57c"], "0bae2cd2-9509-438a-a4ac-b5089822db45": ["faad2e1e-abb7-436f-8a65-5a9238da08a3"], "b9793dff-5675-45ac-918c-8913dacaf24e": ["faad2e1e-abb7-436f-8a65-5a9238da08a3"], "3fae2487-25fa-4f7f-83ae-5b58ca79fcd2": ["14f821e6-12d8-4f1e-885a-f208768abc3a"], "bf78914e-2a0e-4049-b6c4-873ecaffc9f0": ["14f821e6-12d8-4f1e-885a-f208768abc3a"], "8f7ba8bd-968d-4ce2-9e6c-6a56f87d32ed": ["b967f79f-a21a-4f36-a3c5-cd6a55d2f3d7"], "75280ba6-688c-419a-8a93-20cf5b07a15f": ["b967f79f-a21a-4f36-a3c5-cd6a55d2f3d7"], "fe569c3a-eb38-4d80-b8d5-5e50ca70cf34": ["9a07c74c-f5cc-40d4-9b85-f3059546f3c5"], "42f6b56a-8e64-42ff-9ecb-de84650fb057": ["9a07c74c-f5cc-40d4-9b85-f3059546f3c5"], "db0afe55-ce59-4886-b096-029954797356": ["ae7ddbec-b897-412f-8793-57e56083e3c3"], "0d5cbffc-9c1c-4a6a-a8e5-66c442342fb4": ["ae7ddbec-b897-412f-8793-57e56083e3c3"]}, "corpus": {"982bddd4-34de-4203-aa57-d54c408be112": "Is this infrastructure necessary? DeepSeek v3\u2019s $6m training cost and the continued crash in LLM prices might hint that it\u2019s not. But would you want to be the big tech executive that argued NOT to build out this infrastructure only to be proven wrong in a few years\u2019 time?\n\nAn interesting point of comparison here could be the way railways rolled out around the world in the 1800s. Constructing these required enormous investments and had a massive environmental impact, and many of the lines that were built turned out to be unnecessary\u2014sometimes multiple lines from different companies serving the exact same routes!", "45c2370e-5759-4478-b1e4-efceef0e3903": "The resulting bubbles contributed to several financial crashes, see Wikipedia for Panic of 1873, Panic of 1893, Panic of 1901 and the UK\u2019s Railway Mania. They left us with a lot of useful infrastructure and a great deal of bankruptcies and environmental damage.\n\nThe year of slop\n\n2024 was the year that the word \"slop\" became a term of art. I wrote about this in May, expanding on this tweet by @deepfates:\n\nWatching in real time as \u201cslop\u201d becomes a term of art. the way that \u201cspam\u201d became the term for unwanted emails, \u201cslop\u201d is going in the dictionary as the term for unwanted AI generated content\n\nI expanded that definition a tiny bit to this:\n\nSlop describes AI-generated content that is both unrequested and unreviewed.", "abfc7d71-9abd-4e1a-88c6-58cab4f9847e": "I ended up getting quoted talking about slop in both the Guardian and the NY Times. Here\u2019s what I said in the NY TImes:\n\nSociety needs concise ways to talk about modern A.I. \u2014 both the positives and the negatives. \u2018Ignore that email, it\u2019s spam,\u2019 and \u2018Ignore that article, it\u2019s slop,\u2019 are both useful lessons.\n\nI love the term \u201cslop\u201d because it so succinctly captures one of the ways we should not be using generative AI!\n\nSlop was even in the running for Oxford Word of the Year 2024, but it lost to brain rot.\n\nSynthetic training data works great", "aafd1862-f236-4592-858b-f010bee67ce0": "An idea that surprisingly seems to have stuck in the public consciousness is that of \u201cmodel collapse\u201d. This was first described in the paper The Curse of Recursion: Training on Generated Data Makes Models Forget in May 2023, and repeated in Nature in July 2024 with the more eye-catching headline AI models collapse when trained on recursively generated data.\n\nThe idea is seductive: as the internet floods with AI-generated slop the models themselves will degenerate, feeding on their own output in a way that leads to their inevitable demise!\n\nThat\u2019s clearly not happening. Instead, we are seeing AI labs increasingly train on synthetic content\u2014deliberately creating artificial data to help steer their models in the right way.", "e3dbbc53-911e-4237-a5bc-6b07c6de23e5": "One of the best descriptions I\u2019ve seen of this comes from the Phi-4 technical report, which included this:\n\nSynthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data.", "445f11d6-c052-46bc-9372-7bb3c3321b77": "Structured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns.", "7b2e4741-c4a8-4368-8483-9163f636eced": "Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives\u2014a trick used by an increasing number of labs. DeepSeek v3 used \u201creasoning\u201d data created by DeepSeek-R1. Meta\u2019s Llama 3.3 70B fine-tuning used over 25M synthetically generated examples.\n\nCareful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone.\n\nLLMs somehow got even harder to use", "af2325a7-de09-4e9b-8f17-57c5f19b92ec": "A drum I\u2019ve been banging for a while is that LLMs are power-user tools\u2014they\u2019re chainsaws disguised as kitchen knives. They look deceptively simple to use\u2014how hard can it be to type messages to a chatbot?\u2014but in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls.\n\nIf anything, this problem got worse in 2024.\n\nWe\u2019ve built computer systems you can talk to in human language, that will answer your questions and usually get them right! ... depending on the question, and how you ask it, and whether it\u2019s accurately reflected in the undocumented and secret training set.", "fe888d58-fc47-4355-bfd6-a349eb4ff35f": "The number of available systems has exploded. Different systems have different tools they can apply to your problems\u2014like Python and JavaScript and web search and image generation and maybe even database lookups... so you\u2019d better understand what those tools are, what they can do and how to tell if the LLM used them or not.\n\nDid you know ChatGPT has two entirely different ways of running Python now?\n\nWant to build a Claude Artifact that talks to an external API? You\u2019d better understand CSP and CORS HTTP headers first.", "840cbf06-ab90-4d11-a9f9-8d92e31444f0": "The models may have got more capable, but most of the limitations remained the same. OpenAI\u2019s o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it\u2019s running in. o1 can\u2019t run web searches or use Code Interpreter, but GPT-4o can\u2014both in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023).\n\nWhat are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out.", "735cf492-c1fc-4edf-95a1-891bfac88f13": "Meanwhile, it\u2019s increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I\u2019ve seen so many examples of people trying to win an argument with a screenshot from ChatGPT\u2014an inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right.", "210c19b2-e524-45a9-8aba-3635b6f9c15c": "There\u2019s a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can\u2019t see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire!\n\nThere is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads.\n\nKnowledge is incredibly unevenly distributed\n\nMost people have heard of ChatGPT by now. How many have heard of Claude?", "ba7f8038-b4e1-42e7-8ae3-4f53b7d5f57c": "The knowledge gap between the people who actively follow this stuff and the 99% of the population who do not is vast.\n\nThe pace of change doesn\u2019t help either. In just the past month we\u2019ve seen general availability of live interfaces where you can point your phone\u2019s camera at something and talk about it with your voice... and optionally have it pretend to be Santa. Most self-certified nerds haven\u2019t even tried that yet.\n\nGiven the ongoing (and potential) impact on society that this technology has, I don\u2019t think the size of this gap is healthy. I\u2019d like to see a lot more effort put into improving this.\n\nLLMs need better criticism", "faad2e1e-abb7-436f-8a65-5a9238da08a3": "A lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that \u201cLLMs are useful\u201d can be enough to kick off a huge fight.\n\nI get it. There are plenty of reasons to dislike this technology\u2014the environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people\u2019s jobs.\n\nLLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative.", "14f821e6-12d8-4f1e-885a-f208768abc3a": "I like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot of very bad decisions are being made based on that hype. Being critical is a virtue.\n\nIf we want people with decision-making authority to make good decisions about how to apply these tools we first need to acknowledge that there ARE good applications, and then help explain how to put those into practice while avoiding the many unintiutive traps.\n\n(If you still don\u2019t think there are any good applications at all I\u2019m not sure why you made it to this point in the article!)", "b967f79f-a21a-4f36-a3c5-cd6a55d2f3d7": "I think telling people that this whole field is environmentally catastrophic plagiarism machines that constantly make things up is doing those people a disservice, no matter how much truth that represents. There is genuine value to be had here, but getting to that value is unintuitive and needs guidance.\n\nThose of us who understand this stuff have a duty to help everyone else figure it out.\n\nEverything tagged \u201cllms\u201d on my blog in 2024\n\nBecause I undoubtedly missed a whole bunch of things, here\u2019s every long-form post I wrote in 2024 that I tagged with llms:\n\nJanuary\n\n7th: It\u2019s OK to call it Artificial Intelligence\n\n9th: What I should have said about the term Artificial Intelligence\n\n17th: Talking about Open Source LLMs on Oxide and Friends", "9a07c74c-f5cc-40d4-9b85-f3059546f3c5": "26th: LLM 0.13: The annotated release notes\n\nFebruary\n\n21st: The killer app of Gemini Pro 1.5 is video\n\nMarch\n\n5th: Prompt injection and jailbreaking are not the same thing\n\n8th: The GPT-4 barrier has finally been broken\n\n22nd: Claude and ChatGPT for ad-hoc sidequests\n\n23rd: Building and testing C extensions for SQLite with ChatGPT Code Interpreter\n\n26th: llm cmd undo last git commit\u2014a new plugin for LLM\n\nApril\n\n8th: Building files-to-prompt entirely using Claude 3 Opus\n\n10th: Three major LLM releases in 24 hours (plus weeknotes)\n\n17th: AI for Data Journalism: demonstrating what we can do with this stuff right now\n\n22nd: Options for accessing Llama 3 from the terminal using LLM\n\nMay", "ae7ddbec-b897-412f-8793-57e56083e3c3": "May\n\n8th: Slop is the new name for unwanted AI-generated content\n\n15th: ChatGPT in \u201c4o\u201d mode is not running the new features yet\n\n29th: Training is not the same as chatting: ChatGPT and other LLMs don\u2019t remember everything you say\n\nJune\n\n6th: Accidental prompt injection against RAG applications\n\n10th: Thoughts on the WWDC 2024 keynote on Apple Intelligence\n\n17th: Language models on the command-line\n\n21st: Building search-based RAG using Claude, Datasette and Val Town\n\n27th: Open challenges for AI engineering\n\nJuly\n\n14th: Imitation Intelligence, my keynote for PyCon US 2024\n\n19th: Weeknotes: GPT-4o mini, LLM 0.15, sqlite-utils 3.37 and building a staging environment\n\nAugust"}}