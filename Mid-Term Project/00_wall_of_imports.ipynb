{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                                                   # Provides functions for interacting with the operating system (e.g., environment variables, file paths)\n",
    "import json                                                                 # Handles JSON data operations (serialization and deserialization)\n",
    "import requests                                                             # Library for making HTTP requests (e.g., calling APIs)\n",
    "import getpass                                                              # Provides secure password input functionality without disclosing them\n",
    "import pickle                                                               # Used for object serialization and deserialization\n",
    "import dill                                                                 # Extends pickle for better serialization support\n",
    "import traceback                                                            # Provides utilities for error handling and debugging\n",
    "import random                                                               # Generates random numbers and selections\n",
    "import numpy as np                                                          # Required for conducting scientific and mathematical operations \n",
    "import pandas as pd                                                         # Data processing library for conducting data analysis and manipulation\n",
    "import chainlit as cl\n",
    "\n",
    "import re                                                                   # Regular expressions for text processing\n",
    "import mwclient                                                             # For WikiVoyage API access to retrieve travel-related data\n",
    "import concurrent.futures                                                   # For handling parallel execution\n",
    "from bs4 import BeautifulSoup                                               # For parsing HTML content\n",
    "from dataclasses import dataclass, field                                    # For defining structured data objects\n",
    "from statistics import median                                               # For perfoming basic statistical functions\n",
    "\n",
    "from amadeus import Client as AmadeusClient, ResponseError                  # Amadeus API client for fetching travel-related data - Client interacts with the Amadeus API, ResponseError handles exceptions\n",
    "from datasets import Dataset                                                # Handles dataset operations, likely from Hugging Face datasets library\n",
    "from datetime import datetime, timedelta                                    # Date and time handling: Classes for working with dates and times (e.g., handling dates and time calculations)\n",
    "from sklearn.model_selection import train_test_split                        # Splits datasets for machine learning training and testing\n",
    "from sklearn.metrics.pairwise import cosine_similarity                      # Computes cosine similarity between vectors, used for measuring text or feature similarity\n",
    "from pydantic import BaseModel, Field                                       # Tools for data validation and settings management\n",
    "from IPython.display import Image, display                                  # Tools for displaying images in notebooks by using Jupyter notebook display utilities\n",
    "from typing import Dict, List, Any, Optional, Tuple                         # Provides type hints for better code readability and static analysis\n",
    "\n",
    "# LangChain modules for working with LLMs and embeddings\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings                   # Provides OpenAI-based chat and embedding models\n",
    "from langchain.schema import Document                                       # Defines the structure of a Document schema for LangChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter          # Text splitting utility - splits large text into smaller chunks for processing\n",
    "from langchain.vectorstores import FAISS                                    # Vector store - FAISS (Facebook AI Similarity Search) for vector-based retrieval\n",
    "from tqdm.auto import tqdm                                                  # Provides progress bars for loops\n",
    "\n",
    "# LangChain chain-related imports\n",
    "from langchain.chains import create_retrieval_chain                         # Creates chains for document retrieval to eventually create a retrieval-based LLM chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain # Document combination utility (combines retrieved documents for processing)\n",
    "from langchain.chains import LLMChain                                       # Chain component for running LLM-based tasks and workflows\n",
    "from langchain.chat_models import ChatOpenAI                                # OpenAI chat model wrapper for conversational AI\n",
    "\n",
    "# Prompt handling imports\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, MessagesPlaceholder   # Defines prompt templates for LLM interactions\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "# Graph-related imports\n",
    "from langgraph.graph import END, StateGraph                                 # Graph components for workflow\n",
    " \n",
    "# LangChain core components\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage    # Message types for chat (messages exchanged between human and AI)\n",
    "from langchain_core.output_parsers import StrOutputParser                   # Parser for string outputs from LLM responses \n",
    "from langchain_core.runnables import RunnablePassthrough                    # Utility for chain composition allowing simple passthrough execution of functions\n",
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "# Langgraph Graph imports\n",
    "from langgraph.graph import END, StateGraph                                 # Constructs a state graph for managing execution flow in a pipeline\n",
    "from langgraph.checkpoint.base import BaseCheckpointSaver                   # Handles checkpointing execution states in a pipeline\n",
    "from langgraph.prebuilt import create_react_agent                           # Utility for building structured AI agent workflows\n",
    "\n",
    "# Langsmith imports\n",
    "from langsmith import Client as LangsmithClient                             # Debugging and evaluation tool for LangChain\n",
    "from langsmith.evaluation import LangChainStringEvaluator                   # Evaluates the quality of LangChain-generated responses\n",
    "\n",
    "# RAGAS library imports\n",
    "from ragas import evaluate                                                  # Used for using out-of-box evaluation metrics for LLM applications \n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall # Evaluation metrics for assessing response accuracy and relevance\n",
    "\n",
    "# Sentence Transformers and PyTorch imports\n",
    "import torch                                                                  # PyTorch library for deep learning and tensor computations\n",
    "from torch.utils.data import DataLoader                                       # Utility for loading and batching datasets for training models\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses   # Provides tools for training and fine-tuning sentence embeddings\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator     # Evaluates embedding similarity between sentence representations  \n",
    "\n",
    "from safetensors.torch import load_file                                       # Secure method for loading tensor files\n",
    "from huggingface_hub import notebook_login                                    # For logging into Huggingface account via login credentials entered in notebook\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
